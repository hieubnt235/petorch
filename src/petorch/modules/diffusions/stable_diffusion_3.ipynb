{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Components (Migrate from Stable Diffusion)**\n",
    "Quick migration mental model (old → new)\n",
    "\n",
    "1. U-Net → Transformer (MMDiT-X)\n",
    "\n",
    "2. 1× CLIP → 2× CLIP + 1× T5-XXL\n",
    "\n",
    "3. Same VAE role (encode/decode latents)\n",
    "\n",
    "4. DDIM/DPM schedulers → FlowMatch-Euler/Heun (+ shift)\n",
    "\n",
    "5. CFG only → CFG + optional SLG\n"
   ],
   "id": "8951867ab16e162f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **1. Transformer**",
   "id": "60c677dc6aa2de1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T03:26:51.696447Z",
     "start_time": "2025-08-29T03:26:05.059330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from diffusers import SD3Transformer2DModel, TorchAoConfig\n",
    "model_id = \"stabilityai/stable-diffusion-3.5-medium\"\n",
    "ao_cfg = TorchAoConfig(\"int4_weight_only\")\n",
    "\n",
    "transformer = SD3Transformer2DModel.from_pretrained(\n",
    "    model_id,\n",
    "    subfolder=\"transformer\",\n",
    "    quantization_config= ao_cfg,\n",
    ")"
   ],
   "id": "87e833c91a65d218",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding `torch_dtype` with `torch_dtype=torch.bfloat16` due to requirements of `torchao` to enable model loading in different precisions. Pass your own `torch_dtype` to specify the dtype of the remaining non-linear layers, or pass torch_dtype=torch.bfloat16, to remove this warning.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::_convert_weight_to_int4pack' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_convert_weight_to_int4pack' is only available for these backends: [CUDA, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradMAIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastMTIA, AutocastMAIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA_0.cpp:16092 [kernel]\nMeta: registered at /dev/null:488 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:375 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMAIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:13560 [kernel]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocastMAIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:504 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:542 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotImplementedError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m model_id = \u001B[33m\"\u001B[39m\u001B[33mstabilityai/stable-diffusion-3.5-medium\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      3\u001B[39m ao_cfg = TorchAoConfig(\u001B[33m\"\u001B[39m\u001B[33mint4_weight_only\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m transformer = \u001B[43mSD3Transformer2DModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtransformer\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquantization_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mao_cfg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhf_kDgdiIJgVKdasnqKRMFdZgrKDsInzqTDRZ\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m     10\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/diffusers/models/modeling_utils.py:1288\u001B[39m, in \u001B[36mModelMixin.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[39m\n\u001B[32m   1278\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1279\u001B[39m     hf_quantizer.validate_environment(device_map=device_map)\n\u001B[32m   1281\u001B[39m (\n\u001B[32m   1282\u001B[39m     model,\n\u001B[32m   1283\u001B[39m     missing_keys,\n\u001B[32m   1284\u001B[39m     unexpected_keys,\n\u001B[32m   1285\u001B[39m     mismatched_keys,\n\u001B[32m   1286\u001B[39m     offload_index,\n\u001B[32m   1287\u001B[39m     error_msgs,\n\u001B[32m-> \u001B[39m\u001B[32m1288\u001B[39m ) = \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_load_pretrained_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1289\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1290\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1291\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresolved_model_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1292\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1293\u001B[39m \u001B[43m    \u001B[49m\u001B[43mloaded_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1294\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_mismatched_sizes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_mismatched_sizes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1295\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1296\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1297\u001B[39m \u001B[43m    \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1298\u001B[39m \u001B[43m    \u001B[49m\u001B[43moffload_state_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffload_state_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1299\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1300\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1301\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1302\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdduf_entries\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdduf_entries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1303\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_parallel_loading_enabled\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_parallel_loading_enabled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1304\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1305\u001B[39m loading_info = {\n\u001B[32m   1306\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmissing_keys\u001B[39m\u001B[33m\"\u001B[39m: missing_keys,\n\u001B[32m   1307\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33munexpected_keys\u001B[39m\u001B[33m\"\u001B[39m: unexpected_keys,\n\u001B[32m   1308\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmismatched_keys\u001B[39m\u001B[33m\"\u001B[39m: mismatched_keys,\n\u001B[32m   1309\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33merror_msgs\u001B[39m\u001B[33m\"\u001B[39m: error_msgs,\n\u001B[32m   1310\u001B[39m }\n\u001B[32m   1312\u001B[39m \u001B[38;5;66;03m# Dispatch model with hooks on all devices if necessary\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/diffusers/models/modeling_utils.py:1580\u001B[39m, in \u001B[36mModelMixin._load_pretrained_model\u001B[39m\u001B[34m(cls, model, state_dict, resolved_model_file, pretrained_model_name_or_path, loaded_keys, ignore_mismatched_sizes, assign_to_params_buffers, hf_quantizer, low_cpu_mem_usage, dtype, keep_in_fp32_modules, device_map, offload_state_dict, offload_folder, dduf_entries, is_parallel_loading_enabled)\u001B[39m\n\u001B[32m   1577\u001B[39m     shard_files = logging.tqdm(resolved_model_file, desc=\u001B[33m\"\u001B[39m\u001B[33mLoading checkpoint shards\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1579\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m shard_file \u001B[38;5;129;01min\u001B[39;00m shard_files:\n\u001B[32m-> \u001B[39m\u001B[32m1580\u001B[39m     offload_index, state_dict_index, _mismatched_keys, _error_msgs = \u001B[43mload_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshard_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1581\u001B[39m     error_msgs += _error_msgs\n\u001B[32m   1582\u001B[39m     mismatched_keys += _mismatched_keys\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/diffusers/models/model_loading_utils.py:370\u001B[39m, in \u001B[36m_load_shard_file\u001B[39m\u001B[34m(shard_file, model, model_state_dict, device_map, dtype, hf_quantizer, keep_in_fp32_modules, dduf_entries, loaded_keys, unexpected_keys, offload_index, offload_folder, state_dict_index, state_dict_folder, ignore_mismatched_sizes, low_cpu_mem_usage)\u001B[39m\n\u001B[32m    368\u001B[39m error_msgs = []\n\u001B[32m    369\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m low_cpu_mem_usage:\n\u001B[32m--> \u001B[39m\u001B[32m370\u001B[39m     offload_index, state_dict_index = \u001B[43mload_model_dict_into_meta\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    371\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    372\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    373\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    374\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    375\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    376\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    377\u001B[39m \u001B[43m        \u001B[49m\u001B[43munexpected_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43munexpected_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    378\u001B[39m \u001B[43m        \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[43m        \u001B[49m\u001B[43moffload_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffload_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstate_dict_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstate_dict_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstate_dict_folder\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstate_dict_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    384\u001B[39m     assign_to_params_buffers = check_support_param_buffer_assignment(model, state_dict)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/diffusers/models/model_loading_utils.py:306\u001B[39m, in \u001B[36mload_model_dict_into_meta\u001B[39m\u001B[34m(model, state_dict, dtype, model_name_or_path, hf_quantizer, keep_in_fp32_modules, device_map, unexpected_keys, offload_folder, offload_index, state_dict_index, state_dict_folder)\u001B[39m\n\u001B[32m    302\u001B[39m     state_dict_index = offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001B[32m    303\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m is_quantized \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[32m    304\u001B[39m     hf_quantizer.check_if_quantized_param(model, param, param_name, state_dict, param_device=param_device)\n\u001B[32m    305\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m     \u001B[43mhf_quantizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate_quantized_param\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_device\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munexpected_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\n\u001B[32m    308\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    309\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    310\u001B[39m     set_module_tensor_to_device(model, param_name, param_device, value=param, **set_module_kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/diffusers/quantizers/torchao/torchao_quantizer.py:280\u001B[39m, in \u001B[36mTorchAoHfQuantizer.create_quantized_param\u001B[39m\u001B[34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys, **kwargs)\u001B[39m\n\u001B[32m    277\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    278\u001B[39m     \u001B[38;5;66;03m# As we perform quantization here, the repr of linear layers is that of AQT, so we don't have to do it ourselves\u001B[39;00m\n\u001B[32m    279\u001B[39m     module._parameters[tensor_name] = torch.nn.Parameter(param_value).to(device=target_device)\n\u001B[32m--> \u001B[39m\u001B[32m280\u001B[39m     \u001B[43mquantize_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mquantization_config\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_apply_tensor_subclass\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torchao/quantization/quant_api.py:629\u001B[39m, in \u001B[36mquantize_\u001B[39m\u001B[34m(model, config, filter_fn, device)\u001B[39m\n\u001B[32m    627\u001B[39m     handler = _QUANTIZE_CONFIG_HANDLER[\u001B[38;5;28mtype\u001B[39m(config)]\n\u001B[32m    628\u001B[39m     \u001B[38;5;66;03m# for each linear in the model, apply the transform if filtering passes\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m629\u001B[39m     \u001B[43m_replace_with_custom_fn_if_matches_filter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    630\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    631\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhandler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    632\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilter_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    633\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    634\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_args\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    635\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    637\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    638\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[32m    639\u001B[39m \u001B[38;5;250m        \u001B[39m\u001B[33;03m\"\"\"Passing a generic Callable to `quantize_` is no longer recommended and will be deprecated at a later release. Please see https://github.com/pytorch/ao/issues/1690 for instructions on how to pass in workflow configuration instead.\"\"\"\u001B[39;00m\n\u001B[32m    640\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torchao/quantization/quant_api.py:305\u001B[39m, in \u001B[36m_replace_with_custom_fn_if_matches_filter\u001B[39m\u001B[34m(model, replacement_fn, filter_fn, cur_fqn, device, extra_args)\u001B[39m\n\u001B[32m    303\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    304\u001B[39m         model.to(device=device)  \u001B[38;5;66;03m# move to device before quantization\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m305\u001B[39m     model = \u001B[43mreplacement_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mextra_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    306\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[32m    307\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torchao/quantization/quant_api.py:1207\u001B[39m, in \u001B[36m_int4_weight_only_transform\u001B[39m\u001B[34m(module, config)\u001B[39m\n\u001B[32m   1201\u001B[39m     torchao.quantization.utils.recommended_inductor_config_setter()\n\u001B[32m   1203\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(module, \u001B[33m\"\u001B[39m\u001B[33mweight\u001B[39m\u001B[33m\"\u001B[39m), (\n\u001B[32m   1204\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mapplying int8 weight only quant requires module to have weight attribute\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1205\u001B[39m     + \u001B[33m\"\u001B[39m\u001B[33m but \u001B[39m\u001B[38;5;132;01m{module}\u001B[39;00m\u001B[33m does not have one\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1206\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1207\u001B[39m new_weight = \u001B[43m_int4_weight_only_quantize_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1208\u001B[39m module.weight = torch.nn.Parameter(new_weight, requires_grad=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1209\u001B[39m module.extra_repr = types.MethodType(_linear_extra_repr, module)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torchao/quantization/quant_api.py:1179\u001B[39m, in \u001B[36m_int4_weight_only_quantize_tensor\u001B[39m\u001B[34m(weight, config)\u001B[39m\n\u001B[32m   1174\u001B[39m     mapping_type = MappingType.SYMMETRIC\n\u001B[32m   1175\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m group_size == \u001B[32m128\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m group_size == weight.shape[-\u001B[32m1\u001B[39m], (\n\u001B[32m   1176\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMarlinSparseLayout only supports 128 group size or per channel quantization, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgroup_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1177\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1179\u001B[39m new_weight = \u001B[43mto_affine_quantized_intx\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1180\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1181\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmapping_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m    \u001B[49m\u001B[43mblock_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1184\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquant_min\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1185\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquant_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1186\u001B[39m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1187\u001B[39m \u001B[43m    \u001B[49m\u001B[43mzero_point_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mzero_point_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1188\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpreserve_zero\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpreserve_zero\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1189\u001B[39m \u001B[43m    \u001B[49m\u001B[43mzero_point_domain\u001B[49m\u001B[43m=\u001B[49m\u001B[43mzero_point_domain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1190\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_layout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1191\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_hqq\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_hqq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1192\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1193\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m new_weight\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torchao/dtypes/affine_quantized_tensor.py:367\u001B[39m, in \u001B[36mAffineQuantizedTensor.from_hp_to_intx\u001B[39m\u001B[34m(cls, input_float, mapping_type, block_size, target_dtype, quant_min, quant_max, eps, scale_dtype, zero_point_dtype, preserve_zero, zero_point_domain, _layout, use_hqq)\u001B[39m\n\u001B[32m    363\u001B[39m data, scale, zero_point = _layout.post_process(\n\u001B[32m    364\u001B[39m     data, scale, zero_point, block_size\n\u001B[32m    365\u001B[39m )\n\u001B[32m    366\u001B[39m tensor_impl_ctr = get_tensor_impl_constructor(\u001B[38;5;28mtype\u001B[39m(_layout))\n\u001B[32m--> \u001B[39m\u001B[32m367\u001B[39m tensor_impl = \u001B[43mtensor_impl_ctr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mzero_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_layout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\n\u001B[32m    369\u001B[39m     tensor_impl,\n\u001B[32m    370\u001B[39m     block_size,\n\u001B[32m   (...)\u001B[39m\u001B[32m    375\u001B[39m     dtype=input_float.dtype,\n\u001B[32m    376\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torchao/dtypes/uintx/tensor_core_tiled_layout.py:303\u001B[39m, in \u001B[36mTensorCoreTiledAQTTensorImpl.from_plain\u001B[39m\u001B[34m(cls, int_data, scale, zero_point, _layout)\u001B[39m\n\u001B[32m    301\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    302\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m int_data.dim() == \u001B[32m2\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m303\u001B[39m     packed_weight = \u001B[43mquant_2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mint_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    304\u001B[39m     scale = scale.reshape(int_data.shape[\u001B[32m0\u001B[39m], -\u001B[32m1\u001B[39m)\n\u001B[32m    305\u001B[39m     zero_point = (\n\u001B[32m    306\u001B[39m         zero_point.reshape(int_data.shape[\u001B[32m0\u001B[39m], -\u001B[32m1\u001B[39m)\n\u001B[32m    307\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m zero_point \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    308\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    309\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torchao/dtypes/uintx/tensor_core_tiled_layout.py:285\u001B[39m, in \u001B[36mTensorCoreTiledAQTTensorImpl.from_plain.<locals>.quant_2d\u001B[39m\u001B[34m(int_data_2d)\u001B[39m\n\u001B[32m    281\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    282\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m int_data_2d.dtype == torch.int32, (\n\u001B[32m    283\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mtorch.ops.aten._convert_weight_to_int4pack in torch 2.4 expects `int32` dtype\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    284\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m285\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mops\u001B[49m\u001B[43m.\u001B[49m\u001B[43maten\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_convert_weight_to_int4pack\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    286\u001B[39m \u001B[43m    \u001B[49m\u001B[43mint_data_2d\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcontiguous\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_layout\u001B[49m\u001B[43m.\u001B[49m\u001B[43minner_k_tiles\u001B[49m\n\u001B[32m    287\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torch/_ops.py:1243\u001B[39m, in \u001B[36mOpOverloadPacket.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1241\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._has_torchbind_op_overload \u001B[38;5;129;01mand\u001B[39;00m _must_dispatch_in_python(args, kwargs):\n\u001B[32m   1242\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _call_overload_packet_from_python(\u001B[38;5;28mself\u001B[39m, *args, **kwargs)\n\u001B[32m-> \u001B[39m\u001B[32m1243\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mNotImplementedError\u001B[39m: Could not run 'aten::_convert_weight_to_int4pack' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_convert_weight_to_int4pack' is only available for these backends: [CUDA, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradMAIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastMTIA, AutocastMAIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA_0.cpp:16092 [kernel]\nMeta: registered at /dev/null:488 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:375 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMAIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:13560 [kernel]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocastMAIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:504 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:542 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf8ed0a832511d8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "from diffusers import StableDiffusion3Pipeline"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
