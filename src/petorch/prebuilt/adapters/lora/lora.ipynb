{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:40:13.057335Z",
     "start_time": "2025-08-05T13:40:11.086083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from petorch.prebuilt.lora import LoraLinear\n",
    "from pydantic import PositiveInt, NonNegativeFloat\n",
    "from torch import nn\n",
    "\n",
    "from petorch.adapter import AdapterAPI, BaseModelAdaptionConfig, BaseAdapter"
   ],
   "id": "df472e9794acddd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:40:13.080436Z",
     "start_time": "2025-08-05T13:40:13.067335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dummy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_shape = (8, 8)\n",
    "        self.conv = nn.Conv2d(3, 3, 3, padding='same')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(8 * 8 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "        self.fc3 = nn.Linear(100, 16)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        assert input.shape[2:] == self.input_shape, f\"{input.shape[:2]}-{self.input_shape}\"\n",
    "        x = self.conv(input)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LoraLinearConfig(BaseModelAdaptionConfig):\n",
    "    rank: PositiveInt = 8\n",
    "    alpha: PositiveInt = 16\n",
    "    dropout: NonNegativeFloat = 0.1\n",
    "\n",
    "    def dispatch_adapter(self, fpname: str, base_layer: nn.Module, *args, **kwargs) -> BaseAdapter | None:\n",
    "        if isinstance(base_layer, nn.Linear):\n",
    "            return LoraLinear(cast(nn.Linear, base_layer), self)\n",
    "\n",
    "\n",
    "model = Dummy()\n",
    "org_model = deepcopy(model)\n",
    "config = LoraLinearConfig()\n",
    "sample = torch.rand([2, 3, 8, 8])\n",
    "output = org_model(sample)\n",
    "org_model"
   ],
   "id": "d20bb8d745e15e72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dummy(\n",
       "  (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=192, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:40:13.134356Z",
     "start_time": "2025-08-05T13:40:13.123849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(AdapterAPI.add_adapter(model, config))\n",
    "model"
   ],
   "id": "85f307f6a6bf2973",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc1', 'fc2', 'fc3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dummy(\n",
       "  (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): AdaptedLayer(\n",
       "    (base_layer): Linear(in_features=192, out_features=256, bias=True)\n",
       "    (active_adapters): ModuleDict()\n",
       "    (non_active_adapters): ModuleDict(\n",
       "      (default): LoraLinear(\n",
       "        (lora_A): Linear(in_features=192, out_features=8, bias=True)\n",
       "        (lora_B): Linear(in_features=8, out_features=256, bias=True)\n",
       "        (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc2): AdaptedLayer(\n",
       "    (base_layer): Linear(in_features=256, out_features=100, bias=True)\n",
       "    (active_adapters): ModuleDict()\n",
       "    (non_active_adapters): ModuleDict(\n",
       "      (default): LoraLinear(\n",
       "        (lora_A): Linear(in_features=256, out_features=8, bias=True)\n",
       "        (lora_B): Linear(in_features=8, out_features=100, bias=True)\n",
       "        (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc3): AdaptedLayer(\n",
       "    (base_layer): Linear(in_features=100, out_features=16, bias=True)\n",
       "    (active_adapters): ModuleDict()\n",
       "    (non_active_adapters): ModuleDict(\n",
       "      (default): LoraLinear(\n",
       "        (lora_A): Linear(in_features=100, out_features=8, bias=True)\n",
       "        (lora_B): Linear(in_features=8, out_features=16, bias=True)\n",
       "        (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:41:04.682971Z",
     "start_time": "2025-08-05T13:41:04.674090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output2 = model(sample)\n",
    "assert torch.all(output == output2)"
   ],
   "id": "d208dc9f199e59b4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:41:07.209912Z",
     "start_time": "2025-08-05T13:41:07.201361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    AdapterAPI.activate_adapter(model, 'abc')\n",
    "except ValueError as e:\n",
    "    print(e)"
   ],
   "id": "67ba89f9efb5437a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model does not have adapter named `abc`.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:41:10.842337Z",
     "start_time": "2025-08-05T13:41:10.829827Z"
    }
   },
   "cell_type": "code",
   "source": "AdapterAPI.activate_adapter(model)",
   "id": "5710442b8c464642",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:41:28.547071Z",
     "start_time": "2025-08-05T13:41:28.542343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output3 = model(sample)\n",
    "assert not torch.all(output == output3)"
   ],
   "id": "1dcbb41e2b4d726f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:06.821443Z",
     "start_time": "2025-08-05T13:18:06.813150Z"
    }
   },
   "cell_type": "code",
   "source": "AdapterAPI.remove_adapter(model, \"default\")",
   "id": "b90352490368cbae",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:07.855964Z",
     "start_time": "2025-08-05T13:18:07.840227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output4 = model(sample)\n",
    "torch.all(output == output4)"
   ],
   "id": "57adf860b4d74d4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:10.042704Z",
     "start_time": "2025-08-05T13:18:09.778997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "from typing import cast\n",
    "\n",
    "import torch\n",
    "from pydantic import PositiveInt, NonNegativeFloat, BaseModel\n",
    "from torch import nn\n",
    "\n",
    "from petorch.adapter import BaseModelAdaptionConfig, BaseAdapter, AdapterAPI\n",
    "\n",
    "\n",
    "class DummyAdapter(BaseAdapter):\n",
    "    \"\"\"\n",
    "    Dummy LinearLora\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_layer: nn.Linear, config: \"BaseModelAdaptionConfig\"):\n",
    "        assert isinstance(base_layer, nn.Linear), f\"Base layer must has type {nn.Linear}, got {type(base_layer)}.\"\n",
    "        super().__init__(base_layer, config)\n",
    "\n",
    "        self.lora_A = nn.Linear(base_layer.in_features, self.rank)\n",
    "        self.lora_B = nn.Linear(self.rank, base_layer.out_features)\n",
    "        self.lora_dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.scale = getattr(self.config, \"scale\", None) or 1\n",
    "\n",
    "    @property\n",
    "    def rank(self) -> int:\n",
    "        return self.config.rank\n",
    "\n",
    "    @property\n",
    "    def alpha(self) -> float:\n",
    "        return self.config.alpha\n",
    "\n",
    "    @property\n",
    "    def dropout(self) -> float:\n",
    "        return self.config.dropout\n",
    "\n",
    "    @property\n",
    "    def scaling(self) -> float:\n",
    "        return self.scale * self.alpha / self.rank\n",
    "\n",
    "    @classmethod\n",
    "    def pre_validate_config(cls, config: \"BaseModelAdaptionConfig\") -> None:\n",
    "        class ConfigValidator(BaseModel):\n",
    "            rank: PositiveInt\n",
    "            alpha: PositiveInt\n",
    "            dropout: NonNegativeFloat\n",
    "            adapter_name: str\n",
    "\n",
    "        ConfigValidator.model_validate(config, from_attributes=True)\n",
    "\n",
    "    def forward(self, batch_input: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        output = self.base_layer(batch_input)\n",
    "        return (output + self.lora_B(self.lora_A(self.lora_dropout(batch_input))) * self.scaling)\n",
    "\n",
    "\n",
    "class DummySubModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8 * 8 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        x = self.fc1(input)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Dummy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_shape = (8, 8)\n",
    "        self.conv = nn.Conv2d(3, 3, 3, padding=\"same\")\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sub_model = DummySubModel()\n",
    "        self.fc = nn.Linear(100, 16)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        assert input.shape[2:] == self.input_shape, f\"{input.shape[:2]}-{self.input_shape}\"\n",
    "        x = self.conv(input)\n",
    "        x = self.flatten(x)\n",
    "        x = self.sub_model(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyConfig(BaseModelAdaptionConfig):\n",
    "    rank: PositiveInt = 8\n",
    "    alpha: PositiveInt = 16\n",
    "    dropout: NonNegativeFloat = 0.1\n",
    "\n",
    "    def dispatch_adapter(self, fpname: str, base_layer: nn.Module, *args, **kwargs) -> BaseAdapter | None:\n",
    "        if isinstance(base_layer, nn.Linear):\n",
    "            return DummyAdapter(cast(nn.Linear, base_layer), self)\n",
    "\n",
    "\n",
    "def test_api():\n",
    "    adapter_name = \"test_adapter\"\n",
    "    model = Dummy()\n",
    "    org_model = deepcopy(model)\n",
    "    config = DummyConfig(adapter_name=adapter_name)\n",
    "    sample = torch.rand([2, 3, 8, 8])\n",
    "\n",
    "    output1 = org_model(sample)\n",
    "\n",
    "    # Test add_adapter\n",
    "    target_fqn = [\"fc\", \"sub_model.fc1\", \"sub_model.fc2\"]\n",
    "    target_fqn.sort()\n",
    "    fqn = AdapterAPI.add_adapter(model, config)\n",
    "    fqn.sort()\n",
    "    assert fqn == target_fqn\n",
    "\n",
    "\n",
    "test_api()\n"
   ],
   "id": "903a45fd539638c6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T15:44:59.392350Z",
     "start_time": "2025-08-05T15:44:44.108530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Qwen2ForCausalLM, TorchAoConfig\n",
    "from torchao.dtypes import to_nf4\n",
    "from torchao.quantization import register_quantize_module_handler\n",
    "from dataclasses import dataclass\n",
    "from torchao.core.config import AOBaseConfig\n",
    "import torch\n",
    "from torch import nn\n",
    "import types\n",
    "from torchao.utils import get_model_size_in_bytes\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NF4Config(AOBaseConfig):\n",
    "    block_size: int = 64\n",
    "    scaler_block_size: int = 256\n",
    "\n",
    "\n",
    "def linear_module_repr(module: nn.Linear):\n",
    "    return f\"in_features={module.weight.shape[1]}, out_features={module.weight.shape[0]}, weight={module.weight}, dtype={module.weight.dtype}\"\n",
    "\n",
    "\n",
    "@register_quantize_module_handler(NF4Config)\n",
    "def _nf4_weight_only_transform(module: torch.nn.Module, config: NF4Config, ) -> torch.nn.Module:\n",
    "    new_weight = to_nf4(module.weight, config.block_size, config.scaler_block_size)\n",
    "    module.weight = nn.Parameter(new_weight, requires_grad=False)  # Freeze\n",
    "    module.extra_repr = types.MethodType(linear_module_repr, module)\n",
    "    return module\n",
    "\n",
    "\n",
    "config = TorchAoConfig(NF4Config())\n",
    "\n",
    "model = quantized_model = Qwen2ForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", )\n",
    "\n",
    "quantized_model = Qwen2ForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", quantization_config=config)\n",
    "model_size = get_model_size_in_bytes(model)\n",
    "quantized_model_size = get_model_size_in_bytes(quantized_model)\n",
    "print(model_size)  # 2520669824\n",
    "print(quantized_model_size)  # 1273966688\n",
    "print(quantized_model_size / model_size)  # 0.5054079974577425"
   ],
   "id": "8482c5c4f07665be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2520669824\n",
      "1273966688\n",
      "0.5054079974577425\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare peft conv and einsum",
   "id": "139e1d93089af975"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "\n",
    "kernel_size = stride = (1,) * 2\n",
    "c = 512\n",
    "\n",
    "base = nn.Conv2d(c, int(c / 2), 3, 1, 'same', bias=False)\n",
    "\n",
    "lora_A = nn.Conv2d(c, 8, 3, 1, 'same', bias=False)\n",
    "kernel_size = stride = (1,) * 2\n",
    "lora_B = nn.Conv2d(8, int(c / 2), kernel_size, stride, bias=False)\n",
    "\n",
    "print(base_w := base.weight.numel())\n",
    "print(lora_w := (lora_A.weight.numel() + lora_B.weight.numel()))\n",
    "print(lora_w / base_w)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "\n",
    "fw, einw = None, None\n",
    "start = time.time()\n",
    "for i in range(5000):\n",
    "    fw = nn.functional.conv2d(lora_A.weight.transpose(0, 1), lora_B.weight).transpose(0, 1)\n",
    "print(\"time for peft method: \", time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "# Faster\n",
    "for i in range(1000):\n",
    "    einw = torch.einsum(\"o r ..., r i ... -> o i ...\", lora_B.weight, lora_A.weight)\n",
    "\n",
    "print(\"time for einsum method: \", time.time() - start)\n",
    "print(torch.allclose(fw, einw))\n",
    "print(fw.shape == base.weight.shape == einw.shape)"
   ],
   "id": "88c1c261fe628599"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample = torch.randn([2, c, 256, 256])\n",
    "output = base(sample) + lora_B(lora_A(sample))\n",
    "output_fw = nn.functional.conv2d(sample, base.weight + fw, padding='same')\n",
    "output_einw = nn.functional.conv2d(sample, base.weight + einw, padding='same')\n",
    "\n",
    "print(torch.allclose(output, output_fw, atol=1e-5))  # False, max abs\n",
    "print(torch.allclose(output, output_einw, atol=1e-5))  # True\n",
    "print(torch.allclose(output_einw, output_fw, atol=1e-5))\n",
    "\n",
    "print(abs((output - output_fw)).max())  # 3.0\n",
    "print(abs(output - output_einw).max())  # 1.3e-5\n",
    "print(abs(output_fw - output_einw).max())  # 3.0"
   ],
   "id": "d96a8e827f90ed32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lora embedding",
   "id": "22d24f467bab14c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T07:52:17.932474Z",
     "start_time": "2025-08-12T07:52:16.711694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from petorch.utilities import ParamWrapper\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import time\n",
    "\n",
    "bl = nn.Embedding(1000, 100)\n",
    "sample = torch.tensor([3, 10, 100, 888])\n",
    "\n",
    "lora_A = ParamWrapper(weight=torch.empty([bl.num_embeddings, 8]))\n",
    "lora_B = ParamWrapper(weight=torch.empty([8, bl.embedding_dim]))\n",
    "\n",
    "print(lora_A.weight.shape)\n",
    "print(lora_B.weight.shape)\n",
    "delta_w = torch.einsum(\"nr, rd -> nd\", lora_A.weight, lora_B.weight)\n",
    "assert delta_w.shape == bl.weight.shape\n",
    "base_output = bl(sample)\n",
    "\n",
    "n=1000\n",
    "peft_output = None\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "start = time.time()\n",
    "# Faster\n",
    "for i in range (n):\n",
    "    # Peft method\n",
    "    peft_output = base_output + F.embedding(sample, lora_A.weight) @ lora_B.weight\n",
    "print(time.time()-start)\n",
    "\n",
    "for i in range(n):\n",
    "    # Einsum\n",
    "    delta_w = torch.einsum(\"nr, rd -> nd\", lora_A.weight, lora_B.weight)\n",
    "    output = base_output + F.embedding(sample, delta_w)\n",
    "print(time.time()-start)\n",
    "\n",
    "\n",
    "print(output.shape)\n",
    "torch.allclose(output, peft_output)"
   ],
   "id": "85567dd1d7ebbf12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 8])\n",
      "torch.Size([8, 100])\n",
      "0.15405726432800293\n",
      "1.1950695514678955\n",
      "torch.Size([4, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T07:47:01.877784Z",
     "start_time": "2025-08-12T07:47:01.858609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "peft_delta = base_output + F.embedding(sample, lora_A.weight) @ lora_B.weight\n",
    "torch.allclose(output, peft_delta)"
   ],
   "id": "a18e8ef9edc78d26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.3432e-01, -2.1172e+00,  4.3166e-01, -1.6295e+00, -1.1220e+00,\n",
      "          1.7248e+00, -1.8272e-01,  2.0662e-01, -2.8791e-01, -6.0669e-01,\n",
      "         -2.2729e-01, -1.7357e+00,  8.4946e-01, -5.9496e-02,  1.8398e-01,\n",
      "          1.7075e-01, -3.8632e-02,  9.8571e-01, -4.9658e-01, -3.8940e-01,\n",
      "         -7.1554e-01,  9.2620e-01,  6.1269e-01, -2.2790e-01, -6.1774e-02,\n",
      "          5.4722e-02, -1.5909e-01,  1.0175e+00,  7.0021e-01, -1.7216e+00,\n",
      "          8.1432e-01, -1.6610e+00, -3.9571e-02, -5.9692e-01,  6.8152e-01,\n",
      "         -9.6059e-01,  7.6038e-01,  7.4547e-01,  3.4148e-02,  1.4748e+00,\n",
      "         -3.8180e-01, -3.9374e-01, -1.9129e+00, -5.3340e-01, -1.2263e+00,\n",
      "          3.9411e-01, -4.8989e-01,  7.5922e-01, -3.4971e-01, -3.0818e-01,\n",
      "          8.7494e-01,  1.5366e+00, -3.0570e+11, -1.5567e+00, -3.2343e-01,\n",
      "         -1.0933e+00, -1.1252e+00,  3.4023e-01,  2.3946e+00, -2.0378e-01,\n",
      "          2.3632e+13, -2.6458e-01,  5.4479e-01, -1.6183e+00,  2.4298e+00,\n",
      "         -1.5688e-01, -3.1651e-01, -1.0158e+00,  4.0556e-01,  4.4766e-01,\n",
      "          1.0586e+00, -2.3558e+00,  1.0083e-01, -3.3788e-01, -8.2698e-01,\n",
      "          3.8809e-01,  2.3849e-01, -3.4708e-01,  5.2539e-01, -8.0785e-01,\n",
      "         -1.7264e+00,  1.5525e+00,  2.3115e-01,  4.4379e-01,  7.3105e-01,\n",
      "         -1.4982e+00, -8.1769e-01,  2.4336e-01,  5.5131e-01, -5.5488e-01,\n",
      "          1.3557e+00,  3.1393e-01,  4.9947e-01, -1.1493e-01, -7.0689e-01,\n",
      "          1.6428e+00, -1.2982e+00, -6.0953e-01,  4.0524e-01, -9.5340e-02],\n",
      "        [-1.8790e+00, -4.5969e-01,  1.3143e-01, -2.9534e-01, -8.2321e-02,\n",
      "         -7.9534e-01,  1.8076e+00,  4.5964e-01,  3.2263e-01, -7.9449e-01,\n",
      "         -1.2287e+00,  1.8004e-01, -8.4735e-01,  1.4487e+00, -8.4914e-01,\n",
      "         -1.9546e-01, -3.3614e-01, -2.8144e-01, -7.2676e-01,  4.0974e-01,\n",
      "          3.7094e-01, -2.0636e+00,  1.8797e-01, -5.4994e-01, -8.5302e-01,\n",
      "         -6.4559e-01, -4.5407e-01,  7.8241e-01, -9.4508e-01, -9.0996e-01,\n",
      "         -1.1649e+00,  4.9526e-03,  1.2721e+00, -1.6608e+00,  3.7735e-01,\n",
      "          4.8109e-01, -1.3071e+00, -3.2632e-01, -7.8678e-02,  2.3832e+00,\n",
      "         -9.5292e-01, -2.0620e+00,  2.2286e-01, -1.0378e+00, -1.2366e+00,\n",
      "          9.6237e-01,  1.2692e+00,  5.0533e-01,  9.2077e-02,  3.9580e-02,\n",
      "          7.8556e-01,  1.1006e+00, -3.0570e+11, -5.9253e-01, -5.8425e-01,\n",
      "         -7.4762e-01, -9.3599e-01,  7.1301e-01, -1.9884e-01,  2.8960e-01,\n",
      "          2.1395e+13,  5.6586e-01, -6.0037e-01,  1.1806e+00,  7.3006e-01,\n",
      "          4.2622e-01, -8.6724e-02,  1.0479e+00,  2.4342e-01,  3.6420e-01,\n",
      "          3.9222e-02,  5.3601e-01, -8.5027e-01,  1.5678e-01,  5.3562e-01,\n",
      "         -4.0250e-01,  1.1729e+00,  1.3297e+00, -9.3243e-01,  5.6363e-01,\n",
      "         -1.6611e+00,  1.0692e+00,  2.1522e+00,  8.5608e-01, -4.3507e-01,\n",
      "         -2.6514e-01, -1.6003e+00, -1.6975e+00,  6.4300e-01,  1.9007e-01,\n",
      "          1.1624e+00, -6.6645e-01,  1.1196e+00,  1.1873e+00,  6.5335e-01,\n",
      "         -1.9239e+00, -5.0875e-01,  1.7267e+00,  6.6270e-01,  9.9986e-01],\n",
      "        [ 6.0900e-01, -1.2687e+00, -2.6699e-01,  1.3825e+00,  6.2421e-01,\n",
      "          1.4445e+00, -2.2393e-01,  2.6868e-01, -8.1267e-01, -1.7339e+00,\n",
      "          4.6472e-01, -1.0824e+00, -4.6842e-01, -1.3733e+00,  1.2576e+00,\n",
      "         -9.4805e-01,  5.3879e-01, -2.3510e-01, -3.5923e-01, -9.6255e-01,\n",
      "          7.0188e-01,  1.5279e+00, -1.9048e-01, -1.3581e+00, -4.3873e-01,\n",
      "         -2.2175e-02,  8.5027e-01, -1.1520e-01, -5.8878e-01,  1.1216e+00,\n",
      "          5.6574e-01, -1.9890e-01,  6.6624e-01,  8.4154e-03, -9.8182e-01,\n",
      "         -5.2074e-01,  7.2636e-01,  1.7837e-01,  2.4544e-01,  1.1405e+00,\n",
      "          1.3388e+00, -1.4163e+00, -9.5479e-01,  5.3041e-01, -4.1630e-01,\n",
      "          8.3663e-01,  1.3123e+00,  1.0523e+00, -1.3251e+00,  2.8489e+00,\n",
      "          2.3408e+00, -8.6694e-01, -3.0570e+11,  6.3825e-01, -5.7280e-01,\n",
      "          1.1532e+00, -4.6788e-01, -6.3766e-01,  2.0860e-01,  7.1479e-01,\n",
      "          2.1379e+13, -1.7777e+00, -1.3256e+00,  3.8394e-02,  6.7309e-01,\n",
      "         -3.8449e-01,  2.7968e-01,  6.6827e-02,  5.2398e-01, -1.0350e+00,\n",
      "          1.0394e+00,  4.5927e-01,  2.2264e+00,  4.9941e-01, -1.8349e-01,\n",
      "          1.3205e+00,  1.7424e+00,  4.5258e-02, -9.7133e-01,  6.4042e-01,\n",
      "          6.1002e-01,  2.0583e+00, -8.0485e-02,  1.2940e+00, -8.9483e-01,\n",
      "         -4.8889e-01, -1.8055e+00, -4.5173e-02,  2.2758e-01,  1.8657e+00,\n",
      "          1.8986e+00,  1.1731e+00,  5.2025e-01,  2.4955e-01, -7.6902e-01,\n",
      "         -3.2013e-01, -7.7538e-02, -8.1113e-02,  5.6899e-01, -1.3798e+00],\n",
      "        [-9.3183e-01, -2.9859e-01,  1.0960e+00,  7.0061e-01,  1.0537e+00,\n",
      "         -1.3519e-01, -2.1020e+00, -1.1779e+00,  2.1137e+00,  2.9911e-01,\n",
      "         -1.0301e-01, -9.5710e-01, -5.3457e-01, -1.0661e+00,  1.4829e+00,\n",
      "          1.1819e+00,  4.7106e-01,  1.7748e-01, -1.1619e+00, -5.3367e-02,\n",
      "          5.5230e-02,  1.3672e+00,  5.3029e-01,  1.0305e+00, -1.9495e+00,\n",
      "         -3.7348e-01, -3.5746e-01,  4.4205e-01,  1.2966e+00,  5.1459e-01,\n",
      "          1.6643e+00, -1.8082e+00, -7.6920e-01,  2.7792e-01,  9.9100e-01,\n",
      "          4.5689e-01,  3.8172e-01, -1.4353e+00,  8.8022e-01, -1.1489e+00,\n",
      "         -2.6941e-01,  1.2758e+00,  8.6128e-01, -1.4975e+00, -1.7174e+00,\n",
      "          1.9596e+00, -1.6389e+00, -6.0481e-01,  4.6577e-01, -3.2972e-02,\n",
      "         -1.2168e+00, -1.6523e+00, -3.0570e+11,  6.1976e-01,  8.7850e-01,\n",
      "          1.3933e+00, -1.6878e-01,  1.5969e+00, -1.4405e-02,  7.3825e-01,\n",
      "          2.3632e+13, -1.7687e-01, -1.0597e+00,  1.7336e+00,  1.3248e+00,\n",
      "          3.5405e-02,  1.0288e+00,  5.7663e-01,  1.7463e+00,  7.6418e-01,\n",
      "         -4.7339e-01,  7.9221e-02,  1.3054e+00, -1.9766e+00, -1.0016e+00,\n",
      "         -1.3650e-01,  1.1808e+00, -8.3102e-01, -1.2987e+00, -7.6990e-01,\n",
      "         -7.0542e-01,  3.7350e-01,  6.5179e-01, -1.5946e+00, -7.2905e-01,\n",
      "          9.7564e-01, -1.9393e-01,  6.7161e-01, -2.3865e-01, -9.7390e-01,\n",
      "         -1.0581e+00, -4.7644e-01,  1.0596e+00, -8.0713e-01,  1.0873e-01,\n",
      "          1.3564e+00,  1.5854e+00, -1.8628e+00, -2.7522e-01, -1.5784e+00]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df7e80ce6781f4b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T07:47:07.955370Z",
     "start_time": "2025-08-12T07:47:07.941608Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bffb262d038e6681",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T07:38:02.574418Z",
     "start_time": "2025-08-12T07:38:02.409144Z"
    }
   },
   "cell_type": "code",
   "source": "F.embedding(sample, lora_B.weight.T) # eA  = R in",
   "id": "81c35aaab435e9ec",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlora_B\u001B[49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m.\u001B[49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# eA  = R in\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/projects/petorch/.venv/lib/python3.13/site-packages/torch/nn/functional.py:2551\u001B[39m, in \u001B[36membedding\u001B[39m\u001B[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[39m\n\u001B[32m   2545\u001B[39m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[32m   2546\u001B[39m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[32m   2547\u001B[39m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[32m   2548\u001B[39m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[32m   2549\u001B[39m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[32m   2550\u001B[39m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[32m-> \u001B[39m\u001B[32m2551\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mIndexError\u001B[39m: index out of range in self"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6277b958ce6340ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
